# 1. TRAINING
# source format
#  a. field : catagory/doc_key/doc_value
#  b. delimiter : '\t'
#

train = 'WATER_KOREA_TRAIN'
test = 'WATER_KOREA_TEST'

# Local source to HDFS sequence file
java DocToSeq data/tweets-train.tsv train/seq
java PostgresToSeq $train train/seq

# sequence<text,text> to vector<text,value> file
mahout seq2sparse -i train/seq -o train/vec
# training and creating model
mahout trainnb -i train/vec/tfidf-vectors -el -li train/labelindex -o train/model -ow -c


# 2. TESTING 
# Local source to HDFS sequence file using model information.
java DocToVecWithModel train/vec/dictionary.file-0 train/vec/df-count/part-r-00000 data/tweets-test-set.tsv test/vec
java PostgresToVecWithModel train/vec/dictionary.file-0 train/vec/df-count/part-r-00000 $train test/vec

# testing and verifying 
mahout testnb -i test/vec -m train/model -l train/labelindex -ow -o test/out -c

# frequency count of word per catagory
java TopCategoryWords train/model train/labelindex train/vec/dictionary.file-0 train/vec/df-count/part-r-00000


# 3. CLASSIFYING
# classifying
java Classifier train/model train/labelindex train/vec/dictionary.file-0 train/vec/df-count/part-r-00000 data/tweets-test-set.tsv 
java PostgresClassifier train/model train/labelindex train/vec/dictionary.file-0 train/vec/df-count/part-r-00000 $test

